{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5439cc4b",
   "metadata": {},
   "source": [
    "# Call\n",
    "\n",
    "`Call` is a simple object for one-off calls to LLMs. It does not track history or token usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1585981a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from irouter import Call\n",
    "from irouter.base import nb_markdown\n",
    "\n",
    "# To load OPENROUTER_API_KEY from .env file create a .env file at the root of the project with OPENROUTER_API_KEY=your_api_key\n",
    "# Alternatively pass api_key=your_api_key to the Call class\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39974d87",
   "metadata": {},
   "source": [
    "In this notebook we will use free tiers for Moonshot AI's Kimi K2 and Google's Gemma 3N. \n",
    "\n",
    "An overview of all available models can be found by calling `get_all_models`:\n",
    "```python\n",
    "from irouter.base import get_all_models\n",
    "model_slugs = get_all_models()\n",
    "model_slugs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d630975",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"moonshotai/kimi-k2:free\", \"google/gemma-3n-e2b-it:free\"]\n",
    "\n",
    "test_message = \"Who played the guitar solo on Steely Dan's Kid Charlemagne?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e04c5",
   "metadata": {},
   "source": [
    "# Single Model\n",
    "\n",
    "The simplest way to use `Call` is use a single LLM by giving a model slug."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8056ef65",
   "metadata": {},
   "source": [
    "In this example we initialize a `Call` object with the free tier of Moonshot AI's Kimi-K2 LLM.\n",
    "\n",
    "To set the API key you can either set an environment variable for `OPENROUTER_API_KEY` to your project or pass `api_key` when initializing `Call`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b36549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Call(model_names[0])\n",
    "# or\n",
    "# c = Call(model_names[0], api_key=\"your_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5470f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The guitar solo on Steely Dan's *\"Kid Charlemagne\"* was played by **Larry Carlton**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_markdown(c(test_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fdb618",
   "metadata": {},
   "source": [
    "If needed you can get the raw `ChatCompletion` object from a call by setting `raw=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24c0c707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='gen-1754218891-403swd05iCIF6mQJT5BR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The guitar solo on Steely Dan\\'s \"Kid Charlemagne\" was played by **Larry Carlton**.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning=None), native_finish_reason='stop')], created=1754218891, model='moonshotai/kimi-k2:free', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=22, prompt_tokens=40, total_tokens=62, completion_tokens_details=None, prompt_tokens_details=None), provider='Chutes')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(test_message, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778efa79",
   "metadata": {},
   "source": [
    "# Multiple Models\n",
    "\n",
    "Calling multiple models at once is as simple as giving a list of model slugs to `Call`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d77bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = Call(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f458cc7d",
   "metadata": {},
   "source": [
    "If multiple models are giving a call will return a dictionary mapping with LLM slug and response for easy parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06ca1739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'moonshotai/kimi-k2:free': \"The guitar solo on Steely Dan's *Kid Charlemagne* was played by **Larry Carlton**.\",\n",
       " 'google/gemma-3n-e2b-it:free': 'The guitar solo on Steely Dan\\'s \"Kid Charlemagne\" was played by **Steve Gadd**. \\n\\nThis is a bit of a trick question, as Steve Gadd is primarily known as a drummer! He was actually a session musician who played a distinctive, melodic guitar solo on the song, which was recorded using a combination of real guitar and synthesized sounds. It\\'s a very unusual and memorable solo for someone not traditionally known for playing guitar.\\n'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resps = mc(test_message)\n",
    "resps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fb3249",
   "metadata": {},
   "source": [
    "It can then be parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30815641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The guitar solo on Steely Dan's \"Kid Charlemagne\" was played by **Steve Gadd**. \n",
       "\n",
       "This is a bit of a trick question, as Steve Gadd is primarily known as a drummer! He was actually a session musician who played a distinctive, melodic guitar solo on the song, which was recorded using a combination of real guitar and synthesized sounds. It's a very unusual and memorable solo for someone not traditionally known for playing guitar.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_markdown(resps[\"google/gemma-3n-e2b-it:free\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b522a5b",
   "metadata": {},
   "source": [
    "# Image Input\n",
    "\n",
    "`Call` supports passing image URLs or local image paths. Make sure to use a model that supports image input like `gpt-4o-mini`. Sometimes image input models require a system prompt to be passed. The default system prompt for `Call` is empty so you may need to pass a system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c97ccb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.petlandflorida.com/wp-content/uploads/2022/04/shutterstock_1290320698-1-scaled.jpg\" width=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_url = \"https://www.petlandflorida.com/wp-content/uploads/2022/04/shutterstock_1290320698-1-scaled.jpg\"\n",
    "display(Image(url=image_url, width=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2704ef",
   "metadata": {},
   "source": [
    "## Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fb92e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image features a cute corgi puppy sitting down. The puppy has a mix of tan and white fur, with one ear perked up. The background is a soft green blur, suggesting an outdoor setting.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic = Call(\"gpt-4o-mini\", system=\"You analyze images.\")\n",
    "ic(\n",
    "    [\n",
    "        \"https://www.petlandflorida.com/wp-content/uploads/2022/04/shutterstock_1290320698-1-scaled.jpg\",\n",
    "        \"What is in the image?\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba8f83",
   "metadata": {},
   "source": [
    "## Local Image Path\n",
    "\n",
    "Here the same image is passed as a local image path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fe60d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image shows an adorable puppy, likely a Corgi, with a light tan and white coat. The puppy has a sitting posture, one ear upright, and a soft expression. The background appears to be blurred greenery, suggesting an outdoor setting.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic([\"../assets/puppy.jpg\", \"What is in the image?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6804d7",
   "metadata": {},
   "source": [
    "# PDF Input\n",
    "\n",
    "`irouter` handles PDF URL and local PDF file paths out of the box. \n",
    "\n",
    "PDFs are processed as follows:\n",
    "- If the PDF is a local file, it will be processed as `base64`.\n",
    "- If a PDF URL is given and the selected LLM supports native file processing that is the default, which is charged as input tokens.\n",
    "- If a PDF URL is given and the selected LLM does not support native file processing, the `mistral-ocr` engine is used to read the PDF, which costs $2 per 1,000 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c87c313d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The paper introduces the **Transformer**, a new neural network architecture for sequence transduction (e.g., machine translation). Distinctively, it **relies entirely on attention mechanisms**, specifically **multi-head self-attention**, and **eliminates the use of recurrence and convolutions** entirely. The model achieves state-of-the-art results on translation tasks (WMT 2014 English-to-German and English-to-French) while being more parallelizable and computationally efficient.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\"\n",
    "\n",
    "c([pdf_path, \"What is introduced in this paper?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764be628",
   "metadata": {},
   "source": [
    "You can set custom PDF parsers through the `extra_body parameter`. For example if you want free PDF parsing, specify the `pdf-text` engine in the `extra_body` parameter. Check out [this docs page](https://openrouter.ai/docs/features/images-and-pdfs#plugin-configuration) to learn more about the format of `plugins`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "510a3291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The paper introduces the **Transformer**, a **new neural network architecture** for sequence transduction tasks that **relies entirely on attention mechanisms**, eliminating the need for recurrence or convolutions. Key innovations include:\\n\\n1. **Self-attention (Multi-Head Attention)** – A mechanism that allows the model to relate positions within a sequence without sequential computation.  \\n2. **Encoder-decoder stacks** – Composed of layers with **multi-head self-attention** and **position-wise feed-forward networks**, coupled with residual connections and layer normalization.  \\n3. **Positional encodings** – Sinusoidal position embeddings to retain sequence order since recurrence is removed.  \\n4. **Scalable training** – Faster convergence compared to RNN/CNN-based models (e.g., 38.1 BLEU on EN-DE in 12 hours on 8 GPUs).  \\n\\nThe Transformer **departs from recurrent and convolutional layers**, enabling **parallel computation** and **better performance** on machine translation tasks.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_body = {\"plugins\": [{\"id\": \"file-parser\", \"pdf\": {\"engine\": \"pdf-text\"}}]}\n",
    "c([pdf_path, \"What is introduced in this paper?\"], extra_body=extra_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec0bc46",
   "metadata": {},
   "source": [
    "# Messages \n",
    "\n",
    "For certain cases you might want to pass a list of messages to the Call class. For example to simulate a conversation.\n",
    "\n",
    "In that case messages should be defined as a **list of dicts which define `role` and `content`**.\n",
    "\n",
    "NOTE: The `system` parameter will be ignored if you pass a list of messages. Therefore when using this approach optionally also define a system message in your list of messages.\n",
    "\n",
    "Here is an example of a conversation between a user and an assistant with a system message at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c147af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're absolutely right—my mistake! The capital of France, of course, is **Paris**.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The capital of France is Amsterdam.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"No silly, why would you say Amsterdam is the capital of France?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "c = Call(model_names[0])\n",
    "c(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9ab23",
   "metadata": {},
   "source": [
    "I hope this gives you a good overview of how to work with `Call`. If you would like to track history and token usage check out the `Chat` object in `irouter`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
