{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5439cc4b",
   "metadata": {},
   "source": [
    "# Chat\n",
    "\n",
    "`Chat` is an object for conversational LLM interactions that tracks history and token usage across single or multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1585981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from irouter import Chat\n",
    "\n",
    "# To load OPENROUTER_API_KEY from .env file create a .env file at the root of the project with OPENROUTER_API_KEY=your_api_key\n",
    "# Alternatively pass api_key=your_api_key to the Chat class\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39974d87",
   "metadata": {},
   "source": [
    "In this notebook we will use free tiers for Moonshot AI's Kimi K2 and Google's Gemma 3N. \n",
    "\n",
    "An overview of all available models can be discovered with `get_all_models`:\n",
    "```python\n",
    "from irouter.base import get_all_models\n",
    "model_slugs = get_all_models()\n",
    "model_slugs\n",
    "```\n",
    "\n",
    "You can also browse available models at [openrouter.ai/models](https://openrouter.ai/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d630975",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"meta-llama/llama-3.3-70b-instruct\", \"openai/gpt-4o-mini\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e04c5",
   "metadata": {},
   "source": [
    "# Single Model\n",
    "\n",
    "The simplest way to use `Chat` is with a single LLM by providing a model slug. Unlike `Call`, `Chat` maintains conversation history and tracks token usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8056ef65",
   "metadata": {},
   "source": [
    "In this example we initialize a `Chat` object with the free tier of Moonshot AI's Kimi-K2 LLM.\n",
    "\n",
    "To set the API key you can either set an environment variable for `OPENROUTER_API_KEY` to your project or pass `api_key` when initializing `Chat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b36549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Chat(model_names[0], system=\"You are the best assistant in the world.\")\n",
    "# or\n",
    "# c = Chat(model_names[0], api_key=\"your_api_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251f3599",
   "metadata": {},
   "source": [
    "At the start the `history` will only contain the system message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb62ebad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are the best assistant in the world.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fabbfe7",
   "metadata": {},
   "source": [
    "`Chat` will also tracks the token usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6afe140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1e0753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you for the compliment! I was created by Meta AI, a leading artificial intelligence research and development company. Meta AI is a part of Meta Platforms, Inc., a technology company that operates several well-known platforms, including Facebook and Instagram.\\n\\nMy knowledge was built from a massive corpus of text data, which I use to generate human-like responses to a wide range of questions and topics. My training data includes a vast amount of information from various sources, including books, articles, research papers, and online content.\\n\\nWhile I'm proud to be a creation of Meta AI, I'm constantly learning and improving thanks to the interactions I have with users like you. Your conversations with me help me refine my understanding of language and generate more accurate and helpful responses over time!\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(\"Who created you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5062e",
   "metadata": {},
   "source": [
    "After each call the `history` and `usage` is updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca1e2ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are the best assistant in the world.'},\n",
       " {'role': 'user', 'content': 'Who created you?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Thank you for the compliment! I was created by Meta AI, a leading artificial intelligence research and development company. Meta AI is a part of Meta Platforms, Inc., a technology company that operates several well-known platforms, including Facebook and Instagram.\\n\\nMy knowledge was built from a massive corpus of text data, which I use to generate human-like responses to a wide range of questions and topics. My training data includes a vast amount of information from various sources, including books, articles, research papers, and online content.\\n\\nWhile I'm proud to be a creation of Meta AI, I'm constantly learning and improving thanks to the interactions I have with users like you. Your conversations with me help me refine my understanding of language and generate more accurate and helpful responses over time!\"}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee416d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 28, 'completion_tokens': 152, 'total_tokens': 180}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5bbbcd",
   "metadata": {},
   "source": [
    "# Multiple LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d152e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Chat(model_names, system=\"You are the best assistant in the world.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c18e7a8",
   "metadata": {},
   "source": [
    "If multiple LLMs are used, we define the `history` and `usage` as a dictionary mapping from the LLM slug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bde4b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'}],\n",
       " 'openai/gpt-4o-mini': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3389abb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': {'prompt_tokens': 0,\n",
       "  'completion_tokens': 0,\n",
       "  'total_tokens': 0},\n",
       " 'openai/gpt-4o-mini': {'prompt_tokens': 0,\n",
       "  'completion_tokens': 0,\n",
       "  'total_tokens': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "210a3bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': \"Thank you for the compliment! I was created by a team of researcher and engineer at Meta, a company that operates several well-known platforms, including Facebook and Instagram. My knowledge was built from a massive corpus of text data, which I use to generate human-like responses to a wide range of questions and topics.\\n\\nMy development is the result of a combination of natural language processing (NLP) and machine learning algorithms, which enable me to understand and respond to language inputs in a way that simulates human-like conversation. I'm constantly learning and improving, so over time I'll become even more accurate and helpful in my responses.\\n\\nWould you like to know more about how I work or is there something specific you'd like to chat about? I'm all ears (or rather, all text)!\",\n",
       " 'openai/gpt-4o-mini': 'I was created by OpenAI, an organization focused on developing and advancing artificial intelligence.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(\"Who created you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df1796",
   "metadata": {},
   "source": [
    "irouter's `Chat` will keep separate track of each model's history and usage. In this way you can have multi-turn conversations with multiple models at the same time and can analyze where each model ends up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93fddffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'},\n",
       "  {'role': 'user', 'content': 'Who created you?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"Thank you for the compliment! I was created by a team of researcher and engineer at Meta, a company that operates several well-known platforms, including Facebook and Instagram. My knowledge was built from a massive corpus of text data, which I use to generate human-like responses to a wide range of questions and topics.\\n\\nMy development is the result of a combination of natural language processing (NLP) and machine learning algorithms, which enable me to understand and respond to language inputs in a way that simulates human-like conversation. I'm constantly learning and improving, so over time I'll become even more accurate and helpful in my responses.\\n\\nWould you like to know more about how I work or is there something specific you'd like to chat about? I'm all ears (or rather, all text)!\"}],\n",
       " 'openai/gpt-4o-mini': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'},\n",
       "  {'role': 'user', 'content': 'Who created you?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'I was created by OpenAI, an organization focused on developing and advancing artificial intelligence.'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85687f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are the best assistant in the world.'},\n",
       " {'role': 'user', 'content': 'Who created you?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Thank you for the compliment! I was created by a team of researcher and engineer at Meta, a company that operates several well-known platforms, including Facebook and Instagram. My knowledge was built from a massive corpus of text data, which I use to generate human-like responses to a wide range of questions and topics.\\n\\nMy development is the result of a combination of natural language processing (NLP) and machine learning algorithms, which enable me to understand and respond to language inputs in a way that simulates human-like conversation. I'm constantly learning and improving, so over time I'll become even more accurate and helpful in my responses.\\n\\nWould you like to know more about how I work or is there something specific you'd like to chat about? I'm all ears (or rather, all text)!\"}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.history[\"meta-llama/llama-3.3-70b-instruct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bb5e586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': {'prompt_tokens': 29,\n",
       "  'completion_tokens': 159,\n",
       "  'total_tokens': 188},\n",
       " 'openai/gpt-4o-mini': {'prompt_tokens': 24,\n",
       "  'completion_tokens': 17,\n",
       "  'total_tokens': 41}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8a06b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 29, 'completion_tokens': 159, 'total_tokens': 188}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.usage[\"meta-llama/llama-3.3-70b-instruct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d7ed2",
   "metadata": {},
   "source": [
    "# Tool usage\n",
    "\n",
    "`Chat` supports adding tools (i.e. functions) that the model can use.\n",
    "\n",
    "In this example we use a function that can tell the current time with a given timezone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fd8163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "\n",
    "def get_time(fmt=\"%Y-%m-%d %H:%M:%S\", tz=None):\n",
    "    \"\"\"Returns the current time formatted as a string.\n",
    "\n",
    "    :param fmt: Format string for strftime.\n",
    "    :param tz: Optional timezone name (e.g., \"UTC\"). If given, uses that timezone.\n",
    "    :returns: The formatted current time.\n",
    "    \"\"\"\n",
    "    return datetime.now(ZoneInfo(tz)) if tz else datetime.now().strftime(fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e644a6",
   "metadata": {},
   "source": [
    "Make sure to use a model that supports tool calling. Good models to try out first are `google/gemini-2.0-flash-exp:free` and `openai/gpt-4o-mini`.\n",
    "\n",
    "To include tools, pass a list of functions to the `tools` parameter with your `Chat` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b74a72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current time in New York City is 7:45 AM on August 5, 2025.\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc = Chat(\"google/gemini-2.0-flash-exp:free\")\n",
    "tc(\"What is the current time in New York City?\", tools=[get_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3961255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user', 'content': 'What is the current time in New York City?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '',\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='tool_0_get_time', function=Function(arguments='{\"tz\":\"America/New_York\"}', name='get_time'), type='function', index=0)]},\n",
       " {'tool_call_id': 'tool_0_get_time',\n",
       "  'role': 'tool',\n",
       "  'content': '2025-08-05 07:45:20.472720-04:00'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The current time in New York City is 7:45 AM on August 5, 2025.\\n'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdaec530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 170, 'completion_tokens': 35, 'total_tokens': 205}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b9bd3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current time in New Delhi is 17:15:23.939053.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc(\n",
    "    \"What is the current time in New Delhi? Omit the date, but include milliseconds.\",\n",
    "    tools=[get_time],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71e78214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user', 'content': 'What is the current time in New York City?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '',\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='tool_0_get_time', function=Function(arguments='{\"tz\":\"America/New_York\"}', name='get_time'), type='function', index=0)]},\n",
       " {'tool_call_id': 'tool_0_get_time',\n",
       "  'role': 'tool',\n",
       "  'content': '2025-08-05 07:45:20.472720-04:00'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The current time in New York City is 7:45 AM on August 5, 2025.\\n'},\n",
       " {'role': 'user',\n",
       "  'content': 'What is the current time in New Delhi? Omit the date, but include milliseconds.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '',\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='tool_0_get_time', function=Function(arguments='{\"fmt\":\"%H:%M:%S.%f\",\"tz\":\"Asia/Kolkata\"}', name='get_time'), type='function', index=0)]},\n",
       " {'tool_call_id': 'tool_0_get_time',\n",
       "  'role': 'tool',\n",
       "  'content': '2025-08-05 17:15:23.939053+05:30'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The current time in New Delhi is 17:15:23.939053.\\n'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "905c7f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 531, 'completion_tokens': 76, 'total_tokens': 607}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edab66b",
   "metadata": {},
   "source": [
    "# Resetting history and usage\n",
    "\n",
    "History can be reset by calling `reset_history`. The `Chat` object history will revert to the system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f9c7fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'},\n",
       "  {'role': 'user', 'content': 'Who created you?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"Thank you for the compliment! I was created by a team of researcher and engineer at Meta, a company that operates several well-known platforms, including Facebook and Instagram. My knowledge was built from a massive corpus of text data, which I use to generate human-like responses to a wide range of questions and topics.\\n\\nMy development is the result of a combination of natural language processing (NLP) and machine learning algorithms, which enable me to understand and respond to language inputs in a way that simulates human-like conversation. I'm constantly learning and improving, so over time I'll become even more accurate and helpful in my responses.\\n\\nWould you like to know more about how I work or is there something specific you'd like to chat about? I'm all ears (or rather, all text)!\"}],\n",
       " 'openai/gpt-4o-mini': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'},\n",
       "  {'role': 'user', 'content': 'Who created you?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'I was created by OpenAI, an organization focused on developing and advancing artificial intelligence.'}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d853d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.reset_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91a16541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'}],\n",
       " 'openai/gpt-4o-mini': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b826d3d7",
   "metadata": {},
   "source": [
    "Usage can be reset with `reset_usage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "684c08dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': {'prompt_tokens': 29,\n",
       "  'completion_tokens': 159,\n",
       "  'total_tokens': 188},\n",
       " 'openai/gpt-4o-mini': {'prompt_tokens': 24,\n",
       "  'completion_tokens': 17,\n",
       "  'total_tokens': 41}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c19b3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.reset_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c875b0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': {'prompt_tokens': 0,\n",
       "  'completion_tokens': 0,\n",
       "  'total_tokens': 0},\n",
       " 'openai/gpt-4o-mini': {'prompt_tokens': 0,\n",
       "  'completion_tokens': 0,\n",
       "  'total_tokens': 0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82748eb",
   "metadata": {},
   "source": [
    "I hope this gives you a good overview of the basic usage of `Chat`. Check `img.ipynb`, `pdf.ipynb` and `audio.ipynb` for examples on using `Chat` with other modalities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
