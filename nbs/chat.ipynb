{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5439cc4b",
   "metadata": {},
   "source": [
    "# Chat\n",
    "\n",
    "`Chat` is an object for conversational LLM interactions that tracks history and token usage across single or multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1585981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from irouter import Chat\n",
    "\n",
    "# To load OPENROUTER_API_KEY from .env file create a .env file at the root of the project with OPENROUTER_API_KEY=your_api_key\n",
    "# Alternatively pass api_key=your_api_key to the Chat class\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39974d87",
   "metadata": {},
   "source": [
    "In this notebook we will use free tiers for Moonshot AI's Kimi K2 and Google's Gemma 3N. \n",
    "\n",
    "An overview of all available models can be discovered with `get_all_models`:\n",
    "```python\n",
    "from irouter.base import get_all_models\n",
    "model_slugs = get_all_models()\n",
    "model_slugs\n",
    "```\n",
    "\n",
    "You can also browse available models at [openrouter.ai/models](https://openrouter.ai/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d630975",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"meta-llama/llama-3.3-70b-instruct\", \"openai/gpt-4o-mini\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e04c5",
   "metadata": {},
   "source": [
    "# Single Model\n",
    "\n",
    "The simplest way to use `Chat` is with a single LLM by providing a model slug. Unlike `Call`, `Chat` maintains conversation history and tracks token usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8056ef65",
   "metadata": {},
   "source": [
    "In this example we initialize a `Chat` object with the free tier of Moonshot AI's Kimi-K2 LLM.\n",
    "\n",
    "To set the API key you can either set an environment variable for `OPENROUTER_API_KEY` to your project or pass `api_key` when initializing `Chat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b36549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Chat(model_names[0], system=\"You are the best assistant in the world.\")\n",
    "# or\n",
    "# c = Chat(model_names[0], api_key=\"your_api_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251f3599",
   "metadata": {},
   "source": [
    "At the start the `history` will only contain the system message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb62ebad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are the best assistant in the world.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fabbfe7",
   "metadata": {},
   "source": [
    "`Chat` will also tracks the token usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6afe140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1e0753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you for the compliment! I was created by Meta AI, a company that specializes in natural language processing and artificial intelligence. My development is the result of a collaboration between many researcher and engineer teams who work together to push the boundaries of what is possible with language models like me.\\n\\nI\\'m a large language model, which means I was trained on a massive dataset of text from various sources, including books, articles, and online conversations. This training allows me to understand and respond to a wide range of questions and topics.\\n\\nWhile I don\\'t have a single \"creator\" in the classical sense, the Meta AI team has worked tirelessly to develop and refine my language abilities. I\\'m constantly learning and improving, so I appreciate your feedback and interactions, which help me become a better assistant over time!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(\"Who created you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5062e",
   "metadata": {},
   "source": [
    "After each call the `history` and `usage` is updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca1e2ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are the best assistant in the world.'},\n",
       " {'role': 'user', 'content': 'Who created you?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Thank you for the compliment! I was created by Meta AI, a company that specializes in natural language processing and artificial intelligence. My development is the result of a collaboration between many researcher and engineer teams who work together to push the boundaries of what is possible with language models like me.\\n\\nI\\'m a large language model, which means I was trained on a massive dataset of text from various sources, including books, articles, and online conversations. This training allows me to understand and respond to a wide range of questions and topics.\\n\\nWhile I don\\'t have a single \"creator\" in the classical sense, the Meta AI team has worked tirelessly to develop and refine my language abilities. I\\'m constantly learning and improving, so I appreciate your feedback and interactions, which help me become a better assistant over time!'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee416d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 28, 'completion_tokens': 160, 'total_tokens': 188}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5bbbcd",
   "metadata": {},
   "source": [
    "# Multiple LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d152e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Chat(model_names, system=\"You are the best assistant in the world.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c18e7a8",
   "metadata": {},
   "source": [
    "If multiple LLMs are used, we define the `history` and `usage` as a dictionary mapping from the LLM slug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bde4b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'}],\n",
       " 'openai/gpt-4o-mini': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3389abb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': {'prompt_tokens': 0,\n",
       "  'completion_tokens': 0,\n",
       "  'total_tokens': 0},\n",
       " 'openai/gpt-4o-mini': {'prompt_tokens': 0,\n",
       "  'completion_tokens': 0,\n",
       "  'total_tokens': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "210a3bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': 'Thank you for the compliment! I was created by a team of researcher and engineers at Meta AI, a company that specializes in natural language processing and artificial intelligence. My development is the result of a collaboration between many people, including software engineers, linguists, and researchers, who have worked together to design and train me.\\n\\nI\\'m a type of language model, which means that I\\'m a computer program designed to understand and generate human-like language. My primary function is to assist and communicate with users like you, providing information, answering questions, and even generating text on a wide range of topics.\\n\\nWhile I don\\'t have a single \"creator\" in the classical sense, I\\'m proud to be a part of the Meta AI family and to be able to help users like you with their questions and needs!',\n",
       " 'openai/gpt-4o-mini': 'I was created by OpenAI, an artificial intelligence research organization. If you have any questions about my capabilities or how I can assist you, feel free to ask!'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(\"Who created you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df1796",
   "metadata": {},
   "source": [
    "irouter's `Chat` will keep separate track of each model's history and usage. In this way you can have multi-turn conversations with multiple models at the same time and can analyze where each model ends up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93fddffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'},\n",
       "  {'role': 'user', 'content': 'Who created you?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Thank you for the compliment! I was created by a team of researcher and engineers at Meta AI, a company that specializes in natural language processing and artificial intelligence. My development is the result of a collaboration between many people, including software engineers, linguists, and researchers, who have worked together to design and train me.\\n\\nI\\'m a type of language model, which means that I\\'m a computer program designed to understand and generate human-like language. My primary function is to assist and communicate with users like you, providing information, answering questions, and even generating text on a wide range of topics.\\n\\nWhile I don\\'t have a single \"creator\" in the classical sense, I\\'m proud to be a part of the Meta AI family and to be able to help users like you with their questions and needs!'}],\n",
       " 'openai/gpt-4o-mini': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'},\n",
       "  {'role': 'user', 'content': 'Who created you?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'I was created by OpenAI, an artificial intelligence research organization. If you have any questions about my capabilities or how I can assist you, feel free to ask!'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85687f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are the best assistant in the world.'},\n",
       " {'role': 'user', 'content': 'Who created you?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Thank you for the compliment! I was created by a team of researcher and engineers at Meta AI, a company that specializes in natural language processing and artificial intelligence. My development is the result of a collaboration between many people, including software engineers, linguists, and researchers, who have worked together to design and train me.\\n\\nI\\'m a type of language model, which means that I\\'m a computer program designed to understand and generate human-like language. My primary function is to assist and communicate with users like you, providing information, answering questions, and even generating text on a wide range of topics.\\n\\nWhile I don\\'t have a single \"creator\" in the classical sense, I\\'m proud to be a part of the Meta AI family and to be able to help users like you with their questions and needs!'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.history[\"meta-llama/llama-3.3-70b-instruct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bb5e586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': {'prompt_tokens': 28,\n",
       "  'completion_tokens': 162,\n",
       "  'total_tokens': 190},\n",
       " 'openai/gpt-4o-mini': {'prompt_tokens': 24,\n",
       "  'completion_tokens': 33,\n",
       "  'total_tokens': 57}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8a06b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 28, 'completion_tokens': 162, 'total_tokens': 190}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.usage[\"meta-llama/llama-3.3-70b-instruct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d7ed2",
   "metadata": {},
   "source": [
    "# Single-turn tool usage\n",
    "\n",
    "`Chat` supports adding tools (i.e. functions) that the model can use.\n",
    "\n",
    "In this example we use a function that can tell the current time with a given timezone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fd8163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "\n",
    "def get_time(fmt=\"%Y-%m-%d %H:%M:%S\", tz=None):\n",
    "    \"\"\"Returns the current time formatted as a string.\n",
    "\n",
    "    :param fmt: Format string for strftime.\n",
    "    :param tz: Optional timezone name (e.g., \"UTC\"). If given, uses that timezone.\n",
    "    :returns: The formatted current time.\n",
    "    \"\"\"\n",
    "    dt = datetime.now(ZoneInfo(tz)) if tz else datetime.now()\n",
    "    return dt.strftime(fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e644a6",
   "metadata": {},
   "source": [
    "Make sure to use a model that supports tool calling. Good models to try out first are `google/gemini-2.0-flash-exp:free` and `openai/gpt-4o-mini`.\n",
    "\n",
    "To include tools, pass a list of functions to the `tools` parameter with your `Chat` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b74a72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current time in New York City is 14:44:14 on August 19, 2025.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc = Chat(\"openai/gpt-4o-mini\")\n",
    "tc(\"What is the current time in New York City?\", tools=[get_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3961255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user', 'content': 'What is the current time in New York City?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '',\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_7kjN6WvbrhxV3rtSwxz63B5e', function=Function(arguments='{\"fmt\":\"%Y-%m-%d %H:%M:%S\",\"tz\":\"America/New_York\"}', name='get_time'), type='function', index=0)]},\n",
       " {'tool_call_id': 'call_7kjN6WvbrhxV3rtSwxz63B5e',\n",
       "  'role': 'tool',\n",
       "  'content': '2025-08-19 14:44:14'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The current time in New York City is 14:44:14 on August 19, 2025.'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdaec530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 310, 'completion_tokens': 56, 'total_tokens': 366}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b9bd3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current time in New Delhi is 00:14:19.573.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc(\n",
    "    \"What is the current time in New Delhi? Omit the date, but include milliseconds.\",\n",
    "    tools=[get_time],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71e78214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user', 'content': 'What is the current time in New York City?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '',\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_7kjN6WvbrhxV3rtSwxz63B5e', function=Function(arguments='{\"fmt\":\"%Y-%m-%d %H:%M:%S\",\"tz\":\"America/New_York\"}', name='get_time'), type='function', index=0)]},\n",
       " {'tool_call_id': 'call_7kjN6WvbrhxV3rtSwxz63B5e',\n",
       "  'role': 'tool',\n",
       "  'content': '2025-08-19 14:44:14'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The current time in New York City is 14:44:14 on August 19, 2025.'},\n",
       " {'role': 'user',\n",
       "  'content': 'What is the current time in New Delhi? Omit the date, but include milliseconds.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '',\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_4X7Jx0tdI4M9WtFNc8I1qGsf', function=Function(arguments='{\"fmt\":\"%H:%M:%S.%f\",\"tz\":\"Asia/Kolkata\"}', name='get_time'), type='function', index=0)]},\n",
       " {'tool_call_id': 'call_4X7Jx0tdI4M9WtFNc8I1qGsf',\n",
       "  'role': 'tool',\n",
       "  'content': '00:14:19.573463'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The current time in New Delhi is 00:14:19.573.'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "905c7f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 814, 'completion_tokens': 101, 'total_tokens': 915}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae194cb0",
   "metadata": {},
   "source": [
    "# Multi-turn tool usage\n",
    "\n",
    "Due to `irouter`'s tool implementation, you can also use tools in scenarios where it needs multiple turns to complete. \n",
    "\n",
    "Below we show an example where the models needs to call both a weather and a distance tool multiple times to figure out different parts of a trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb3a67fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's the information for your trip:\\n\\n### Weather:\\n- **Paris**: Sunny, 22°C\\n- **London**: Cloudy, 15°C\\n- **Tokyo**: Rainy, 18°C\\n\\n### Distances:\\n- **Paris to London**: 344 km\\n- **London to Tokyo**: Distance not available.\\n\\nIf you need any further details or assistance, feel free to ask!\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_weather(city):\n",
    "    \"\"\"Get weather for a city (simulated).\n",
    "\n",
    "    :param city: City name\n",
    "    :returns: Weather description\n",
    "    \"\"\"\n",
    "    weather_db = {\n",
    "        \"paris\": \"Sunny, 22°C\",\n",
    "        \"london\": \"Cloudy, 15°C\",\n",
    "        \"tokyo\": \"Rainy, 18°C\",\n",
    "    }\n",
    "    return weather_db.get(city.lower(), \"Weather data not available\")\n",
    "\n",
    "\n",
    "def calculate_distance(city1, city2):\n",
    "    \"\"\"Calculate distance between cities (simulated).\n",
    "\n",
    "    :param city1: First city\n",
    "    :param city2: Second city\n",
    "    :returns: Distance in km\n",
    "    \"\"\"\n",
    "    distances = {\n",
    "        (\"paris\", \"london\"): 344,\n",
    "        (\"london\", \"paris\"): 344,\n",
    "        (\"paris\", \"tokyo\"): 9715,\n",
    "        (\"tokyo\", \"paris\"): 9715,\n",
    "    }\n",
    "    key = (city1.lower(), city2.lower())\n",
    "    return distances.get(key, \"Distance not available\")\n",
    "\n",
    "\n",
    "tc(\n",
    "    \"I'm planning a trip from Paris to London, then to Tokyo. What's the weather like in each city and what are the distances?\",\n",
    "    tools=[get_weather, calculate_distance],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31b24267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 1639, 'completion_tokens': 285, 'total_tokens': 1924}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edab66b",
   "metadata": {},
   "source": [
    "# Resetting history and usage\n",
    "\n",
    "History can be reset by calling `reset_history`. The `Chat` object history will revert to the system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f9c7fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'},\n",
       "  {'role': 'user', 'content': 'Who created you?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Thank you for the compliment! I was created by a team of researcher and engineers at Meta AI, a company that specializes in natural language processing and artificial intelligence. My development is the result of a collaboration between many people, including software engineers, linguists, and researchers, who have worked together to design and train me.\\n\\nI\\'m a type of language model, which means that I\\'m a computer program designed to understand and generate human-like language. My primary function is to assist and communicate with users like you, providing information, answering questions, and even generating text on a wide range of topics.\\n\\nWhile I don\\'t have a single \"creator\" in the classical sense, I\\'m proud to be a part of the Meta AI family and to be able to help users like you with their questions and needs!'}],\n",
       " 'openai/gpt-4o-mini': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'},\n",
       "  {'role': 'user', 'content': 'Who created you?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'I was created by OpenAI, an artificial intelligence research organization. If you have any questions about my capabilities or how I can assist you, feel free to ask!'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d853d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.reset_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91a16541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'}],\n",
       " 'openai/gpt-4o-mini': [{'role': 'system',\n",
       "   'content': 'You are the best assistant in the world.'}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b826d3d7",
   "metadata": {},
   "source": [
    "Usage can be reset with `reset_usage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "684c08dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': {'prompt_tokens': 28,\n",
       "  'completion_tokens': 162,\n",
       "  'total_tokens': 190},\n",
       " 'openai/gpt-4o-mini': {'prompt_tokens': 24,\n",
       "  'completion_tokens': 33,\n",
       "  'total_tokens': 57}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c19b3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.reset_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c875b0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/llama-3.3-70b-instruct': {'prompt_tokens': 0,\n",
       "  'completion_tokens': 0,\n",
       "  'total_tokens': 0},\n",
       " 'openai/gpt-4o-mini': {'prompt_tokens': 0,\n",
       "  'completion_tokens': 0,\n",
       "  'total_tokens': 0}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82748eb",
   "metadata": {},
   "source": [
    "I hope this gives you a good overview of the basic usage of `Chat`. Check `img.ipynb`, `pdf.ipynb` and `audio.ipynb` for examples on using `Chat` with other modalities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
